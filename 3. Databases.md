## **RDS: Managed Database Service** 

RDS offers six DB engines to choose from: MYSQL, MARIADB, Oracle, PostgreSQL, AURORA, MSSQL
MySQL and Maria DB both support multiple storage engines, AWS recommends using them with InnoDB for better compatibility with automated backup and other services.
Aurora is compatible with MySQL or PostgreSQL depending on the version you choose. Offers better write performance than both as it uses a virtualized storage layer.
RDS provides two models for licensing: License included and BYOL

**Data encryption at rest (KMS) is supported. To encrypt an existing RDS instance. Snapshot > copy > choose encryption > restore copied Snapshot **


Manual Backups are taken by users. Persist unless deleted.
Automated backups are enabled by default. They are snapshots of the EBS volume attached to the DB instance. They can be retained for upto 35 days. **When retention period is set to zero => automated backups are disabled. Backups are stored in S3 at no extra cost.** Users need to configure a 30 min backup window for these as IOPS may be suspended.

The first snapshot of a DB instance contains the data for the full DB instance. Subsequent snapshots of the same DB instance are incremental, which means that only the data that has changed after your most recent snapshot is saved.
Restore results in a new DB instance with a new DNShostname
**Creating a DB snapshot on a Single-AZ DB instance results in a brief I/O suspension that can last from a few seconds/minutes**, depending on the size and class of DB instance. Multi-AZ DB instances are not affected by this I/O suspension as the backup is taken on the standby.
With Amazon RDS, you can copy automated or manual DB snapshots. After you copy a snapshot, the copy is a manual snapshot. You cant copy to/from AWS regions in china or govcloud. 
You can share a manual snapshot with up to 20 other AWS accounts.
Automated backup allows point in time recovery. DB change logs are archived to s3 every 5 mins. You can restore to any point in time during your backup retention period.

* Recovery Point Objective (RPO): maximum period of data loss acceptable.
* Recovery Time Objective (RTO): maximum allowed downtime for recovery 

RDS maintenance window - AWS requires at least a 30-minute window in your instance's weekly schedule to confirm that all instances have the latest patches and upgrades. During the maintenance window, tasks are performed on clusters and instances. For the security and stability of your data, maintenance can cause instances to be unavailable. This is different from the 30 mins backup window

RDS multiAZ(High Availability):
Deploy multiple DB instances in different AZs. One primary instance handles read/write. Standby instance is present in another AZ to provide automatic failover protection. 
Causes for DB instance outage: 

-	AZ outage.
-	Changing DB instance type. 
-	OS patching.

Automatic backups are taken from secondary to reduce performance hit

synchronous replication between primary and secondary instances. i.e. secondary sends ack for every data sync, and only then the next data block is written. Replication may introduce latency hence it is recommended to use EBS optimized instances and Provisioned IOPS storage for multiAZ.

All DB engines implement this slightly differently. If you enable multiAZ in production its a big performance hit (no reboot). Make sure to do it in a maintenance window.

**RDS read replica (scalability):**
Read replicas allow horizontal scaling of DB instances. It takes some query load off the master DB instance. You can have upto 5 read replicas and upto 15 aurora replicas. Read replicas and master can be in different AZ or region (helps with DR-cross region migration). They are not the best candidate for failover due to the asynchronous nature of data replication. However, it is possible to promote a read replica to primary manually. Must have automatic back up enabled for the read replica to work. Reporting servers may use read replicas for their work.


**Replication**
The primary difference between synchronous replication and asynchronous replication is the way in which data is written to the replica. Most synchronous replication products write data to primary storage and the replica simultaneously. As such, the primary copy and the replica should always remain synchronized.
In contrast, asynchronous replication products copy the data to the replica after the data is already written to the primary storage. Although the replication process may occur in near-real-time, it is more common for replication to occur on a scheduled basis. For instance, write operations may be transmitted to the replica in batches on a periodic basis (for example, every one minute). In case of a fail-over event, some data loss may occur.
RDS instance class

DB instance class determine the memory and compute capacity. Three types:
1. Standard: Balance of compute memory and network resources. Db.m5 is the latest generation. Most instances are EBS optimized
2. Memory optimized: used when hefty performance requirements are needed. EBS optimized. Latest is dbz1.d used for memory intensive applications. 
3. Burstable: these are non-prod instances that provide a baseline performance with ability to burst to full cpu usage. Non-EBS optimized

 
**DB instance storage:** 
**General purpose SSD(gp2)**: Cost effective solution for most DB workloads. Upto 16 TB volume can be allocated for SQL server. Others can go upto 64 TB. For each Gigabyte allocated to a volume AWS allocates a baseline performance of 3 IOPS, upto 10000 IOPS per volume. E.g. a 20 GB volume would get 60 IOPS. This means larger the volume, better performance you will get. A 1TB volume would get 3000IOPS. 

Maximum disk throughput offered by general purpose SSD is 1280 Mbps.(10000 IOPS) 

**Provisioned IOPS SSD (io1)**: 
It lets you allocate the number of IOPS at the time of instance creation. No concept of bursting. Number of IOPS you allocate is what you pay for irrespective of usage. It is useful for DBs that do transaction processing. IOPS are decided based on the throughput of the instance class chosen. Ratio of IOPS:storage should not be less than 50:1.

**Magnetic storage**: 1000 IOPS upto 4TB.


**Option group**: An option group can specify features, called options, that are available for a particular Amazon RDS DB instance. Options can have settings that specify how the option works. When you associate a DB instance with an option group, the specified options and option settings are enabled for that DB instance. E.g. memcached support for MYSQL or any other type of plugin support.

You manage your DB engine configuration by associating your DB instances with **parameter groups**. Amazon RDS defines parameter groups with default settings that apply to newly created DB instances. A DB parameter group acts as a container for engine configuration values that are applied to one or more DB instances. Parameter group change requires a reboot. Some of the settings that may be modified using parameter groups are: port, max number of connections, cache size etc.

## Amazon Aurora:
Compatible with MySQL and POSTGRES.
When you create an Aurora instance. You create a Cluster.
An Amazon Aurora DB cluster consists of one or more DB instances and a cluster volume that manages the data for those DB instances. An Aurora cluster volume is a virtual database storage volume that spans multiple Availability Zones, with each Availability Zone having a copy of the DB cluster data. Two types of instances in cluster:

1. Primary Instance: Supports read and write and performs all data modifications to cluster volume.
2. Aurora Replica : Using the same cluster volume they support read operations only. You may have upto 15 aurora replicas and for high availability they can be placed in different AZs. Automatic failover to replica is supported.

The terms primary instance and Aurora Replica don't apply to multi-master clusters. An aurora setup with one node is still a cluster because the storage is distributed.

As Aurora uses clusters, endpoints are used to abstract DB connections. 
1. Cluster Endpoints: these are writer endpoints, only these can perform a write operation
2. Reader endpoint: Provides load balancing for read operations.
3. Custom endpoints: endpoint for a set of DB instances that you choose. Can not be used with aurora serverless.
An Instance endpoint connects to a specific DB instance within an Aurora cluster
Amazon Aurora supports two types of instance classes: Memory Optimized (db.r5, db.r4, db.r3) and Burstable Performance(db.t2, db.t3).

Aurora data is stored in the cluster volume, which is a single, virtual volume that uses solid state drives (SSDs). A cluster volume consists of copies of the data across 3 Availability Zones in a single AWS Region. Because the data is automatically replicated across Availability Zones, your data is highly durable with less possibility of data loss. This replication also ensures that your database is more available during a failover. 

Storage scaling: Aurora cluster volumes automatically grow as the amount of data in your database increases. An Aurora cluster volume can grow to a maximum size of 64 tebibytes (TiB). you are only charged for the storage you use.

You can achieve read scaling for your Aurora DB cluster by creating up to 15 Aurora Replicas in a DB cluster that uses single-master replication. Each Aurora Replica returns the same data from the cluster volume with minimal replica lagâ€”usually considerably less than 100 milliseconds after the primary instance has written an update. As your read traffic increases, you can create additional Aurora Replicas and connect to them directly to distribute the read load for your DB cluster. Aurora Replicas don't have to be of the same DB instance class as the primary instance.

**Amazon Aurora Serverless** is an on-demand, autoscaling configuration for Amazon Aurora. An Aurora Serverless DB cluster is a DB cluster that automatically starts up, shuts down, and scales up or down its compute capacity based on your application's needs. Aurora Serverless provides a relatively simple, cost-effective option for infrequent, intermittent, or unpredictable workloads. It can provide this because it automatically starts up, scales compute capacity to match your application's usage, and shuts down when it's not in use.
You can choose to pause your Aurora Serverless DB cluster after a given amount of time with no activity.The default is five minutes. You can also disable pausing the DB cluster.
**When the DB cluster is paused, no compute or memory activity occurs, and you are charged only for storage. If database connections are requested when an Aurora Serverless DB cluster is paused, the DB cluster automatically resumes and services the connection requests.**
The DB instances in an Aurora Serverless cluster only have associated DB cluster parameter groups, not DB parameter groups. Serverless clusters rely on DB cluster parameter groups because DB instances are not permanently associated with Aurora Serverless clusters. 
You can access your Aurora Serverless DB cluster using the built-in Data API. Using this API, you can access Aurora Serverless with web servicesâ€“based applications, including AWS Lambda, AWS AppSync, and AWS Cloud9 using SDK.

**Multi Master clusters:** For each new Amazon Aurora cluster, you can choose whether to create a single-master or multi-master cluster.
Most kinds of Aurora clusters are single-master clusters. e.g., provisioned, Aurora Serverless , parallel query, and Global Database clusters are all single-master clusters. In a single-master cluster, a single DB instance performs all write operations and any other DB instances are read-only. If the writer DB instance becomes unavailable, a failover mechanism promotes one of the read-only instances to be the new writer.
In a multi-master cluster, all DB instances can perform write operations. The notions of a single read-write primary instance and multiple read-only Aurora Replicas don't apply. There isn't any failover when a writer DB instance becomes unavailable, because another writer DB instance is immediately available to take over the work of the failed instance. We refer to this type of availability as continuous availability, to distinguish it from the high availability (with brief downtime during failover) offered by a single-master cluster.
The main design consideration and performance tuning goal with Aurora multi-master clusters is to divide your write operations between DB instances in a way that minimizes write conflicts. That is why multi-master clusters are well-suited for sharded applications. 

## Amazon Redshift: 

It is a data warehouse based on postgres.
1. DBs are used for transaction processing. DWs are used for analytical processing. 
2. DBs are built for simple SQL queries with emphasis on writes. DWs use complex queries with focus on reads. 
3. DBs store current transactions for business processes. DWs store historical data for reporting. 

*Redshift uses columnar storage, meaning it stores the values of a column close together. This reduces the overall discIO requirements as OLAP applications look at multiple records at the same time. As similar types of data are stored together it results in efficient compression. DWs are used for business intelligence and may get data from multiple sources*

A redshift cluster contains one or more compute nodes. *There are two types of nodes. Dense compute - high performance less storage. Dense storage - storage intensive with SSDs*. For clusters with more than one node Redshift also includes a leader node. Leader node coordinates between nodes as well as talks to clients. Leader nodes do not incur costs. Data is encrypted in transit and at rest. Redshift supports single AZ deployment. 

Workload Management(WLM) in redshift allows users to manage priorities among workloads, so that fast running queries are not stuck behind long running queries during runtime. If long running queries are already running then short queries would have to wait. Users can segregate short/long queries in different queues.

*Amazon Redshift enhanced VPC routing*:  Amazon Redshift forces all COPY and UNLOAD traffic between your cluster and your data repositories through your Amazon VPC. By using enhanced VPC routing, you can use standard VPC features, such as VPC security groups, network access control lists (ACLs), VPC endpoints, VPC endpoint policies, internet gateways, and Domain Name System (DNS) servers.
*Redshift supports cross region snapshots.*

You can enable encryption when you launch your cluster, or you can modify an unencrypted cluster to use AWS KMS encryption. To do so, you can use either an AWS-managed key or a CMK. When you modify your cluster to enable KMS encryption, Amazon Redshift automatically migrates your data to a new encrypted cluster. Snapshots created from the encrypted cluster are also encrypted. You can also migrate an encrypted cluster to an unencrypted cluster by modifying the cluster and changing the Encrypt database option. 
Amazon Redshift uses a hierarchy of encryption keys to encrypt the database. You can use either AWS Key Management Service (AWS KMS) or a hardware security module (HSM) to manage the top-level encryption keys in this hierarchy. The process that Amazon Redshift uses for encryption differs depending on how you manage keys. Amazon Redshift automatically integrates with AWS KMS but not with an HSM. When you use an HSM, you must use client and server certificates to configure a trusted connection between Amazon Redshift and your HSM.

## DynamoDB:

 NoSQL database. It supports key:value stores and document stores.  End users just need to specify R/W per second and it would support that. If you are unsure, DynamoDB also supports auto scaling. Data is replicated across three regions stored on SSD. These data bases are suitable for queries involving the primary key. 
No SQL databases don't have a schema and can be created with the primary key, rest of the data can be multi structured. In Relational DB you need to know all attributes in advance. 
Two options for read data consistency:
1. Eventually consistent reads (default): fast reads but data may not be consistent
2. Strongly consistent reads: wait until data is consistent. Slower reads.

It is possible to have a primary key which is a combination of a partition key(2048B max) and sort key(1024B max). This is called a composite primary key.  
Dynamo DB stores tables across AZs. [Global Tables: Multi-Region Replication with DynamoDB - Amazon DynamoDB](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.html)

[Choosing the Right DynamoDB Partition Key](https://aws.amazon.com/blogs/database/choosing-the-right-dynamodb-partition-key/)

All items with the same partition key are stored together and sorted using sort key. 
Secondary index: Alternative index to query data in addition to primary key. 


Query vs Scan
Query finds values based on the primary key. Scan option scans the whole table and secondary index and returns all items.

[DynamoDB Streams Use Cases and Design Patterns | AWS Database Blog](https://aws.amazon.com/blogs/database/dynamodb-streams-use-cases-and-design-patterns/)

Dynamodb accelerator (DAX): in memory cache

[Read/Write Capacity Mode - Amazon DynamoDB](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html)

If you enable DynamoDB auto scaling for a table that has one or more global secondary indexes, we highly recommend that you also apply auto scaling uniformly to those indexes. You can do this by choosing Apply same settings to global secondary indexes in the AWS Management Console.
